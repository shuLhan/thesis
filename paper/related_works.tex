Vandalism detection in Wikipedia based on machine learning approach
became an interesting research topic since 2008.
Potthast et al. \cite{potthast2008automatic} contribution is the first vandalism
detection approach using machine learning with textual and basic
metadata features using Logistic Regression classifier.
Smets et al. \cite{smets08automaticvandalism} use Naive Bayes classifier on
selected words that representing vandalism edit and the first who use
compression model to detect vandalism in Wikipedia.
Itakura and Clarke \cite{itakura2009using} use Dynamic Markov Compression to
detect vandalism edit in Wikipedia.
Mola Velasco \cite{mola2012wikipedia} extend the Potthast research by adding
more textual features and word-list features.
West and Lee \cite{west2011multilingual} use spatial and temporal metadata
without required to check the text in the article and revision, and the first
to introduce \textit{ex post facto} data as feature, where prediction
take the next revision into consideration.
Adler et al. \cite{adler2011wikipedia} build a vandalism detection system using
reputation called WikiTrust and then combine it with
natural language, spatial and temporal features.
Harpalani et al. \cite{harpalani2011language} propose that vandalism has
a unique and equal lingustic property.
They build a system for detecting vandalism based on \textit{stylometric}
analysis from vandalism edit with \textit{context-free grammar} probabilistic
model.
Following the trend of classifying on cross-language vandalism, Tran and
Christen \cite{tran2013cross} evaluated several classifier based on
language feature collected from number of article viewed every hours and the
history of their edit in Wikipedia.

Gotze \cite{gotze2014advanced} combine features from
\cite{potthast2008automatic},
\cite{mola2012wikipedia},
\cite{west2011multilingual},
\cite{adler2011wikipedia},
\cite{javanmardi2011vandalism},
and
\cite{wang2010got},
with four additional and modified features.
Gotze use the random oversampling technique, to overcome imbalance problem,
called
\textit{Synthetic Minority Over-sampling TEchnique} (SMOTE)
proposed by Chawla et al.
\cite{chawla2002smote}.
Original and resampled dataset of PAN-WVC-10 then tested with two-class
classifier:
\textit{Logistic Regression},
\textit{RealAdaBoost},
\textit{Random Forest} (RF), and
\textit{Bayesian Network}.
His evaluation on original dataset showed that RF give better result than
others classifiers.
The result from resampling dataset showed increasing in performance on all
classifiers except RF.

From the previous research, seven of them
(
\cite{mola2012wikipedia}
\cite{west2011multilingual}
\cite{adler2011wikipedia}
\cite{harpalani2011language}
\cite{gotze2014advanced}
\cite{wang2010got}
\cite{adler2010detecting}
)
use PAN-WVC-10,
with the best precision value is $0.86$ and recall value is $0.57$, which
obtained by Velasco using RF without resampling on dataset.
Only two research
(
\cite{west2011multilingual}
\cite{gotze2014advanced}
)
that use PAN-WVC-11
with the best result obtained by Gotze, $0.92$ on precision and $0.39$
on recall.
