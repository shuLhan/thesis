Vandalism detection in Wikipedia based on machine learning approach
became an interesting research topic since 2008.
Potthast \cite{potthast2008automatic} contribution is the first vandalism
detection approach using machine learning with textual and basic
metadata features using Logistic Regression classifier.
Smets \cite{smets08automaticvandalism} use Naive Bayes classifier on selected
words that representing vandalism edit and the first who use compression model
to detect vandalism in Wikipedia.
Itakura and Clarke \cite{itakura2009using} use Dynamic Markov Compression to
detect vandalism edit in Wikipedia.
Mola Velasco \cite{mola2012wikipedia} extend the Potthast research by adding
more textual features and word-list features.
Velasco win the \textit{1st International Competition on Wikipedia Vandalism
Detection}.
West et al. \cite{west2011multilingual} use spatial and temporal metadata
without required to check the text in article and revision.
Adler et al. \cite{adler2011wikipedia} build a vandalism detection system using
reputation called WikiTrust.
Adler et al. \cite{adler2011wikipedia} then combine their previous work with
natural language, spatial and temporal features.
West and Lee \cite{west2011multilingual} is the first who introduce
\textit{ex post facto} data as feature, where their prediction take the next
revision into consideration.
Vandalism detection system from West and Lee win the \textit{2nd International
Competition on Wikipedia Vandalism Detection}.
Harpalani et al. \cite{harpalani2011language} propose that vandalism has
a uniq and equal lingustic property, they then build a system for detecting
vandalism based on \textit{stylometric} analysis from vandalism edit with
\textit{context-free grammar} probabilistic model.
Their approach overcome feature based system with short pattern, which equalize
syntactic structure with token of text.
Following the trend of classifying on cross-language vandalism, Tran and
Christen \cite{tran2013cross} evaluated several classifier based on
language feature collected from number of article viewed every hours and the
history of their edit in Wikipedia.

Gotze \cite{gotze2014advanced} combine feature from
Adler et al. \cite{adler2011wikipedia},
Javanmardi et al. \cite{javanmardi2011vandalism},
Mola Velasco \cite{mola2012wikipedia},
Potthast et al. \cite{potthast2008automatic},
Wang and McKeown \cite{wang2010got}, and
West and Lee \cite{west2011multilingual}
with four additional and modified features.

To overcome imbalance problem, Gotze use the random oversampling technique
called
\textit{Synthetic Minority Over-sampling TEchnique} (SMOTE)
proposed by Chawla
\cite{chawla2002smote}.
Original and resampled dataset of PAN-WVC-10 then tested with two-class
classifier:
\textit{Logistic Regression},
\textit{RealAdaBoost},
\textit{Random Forest} (RF), dan
\textit{Bayesian Network}.
His evaluation on original dataset showed that RF give better result than
others classifiers.
The result from resampling dataset showed increasing in performance on all
classifiers except RF.

From the previous research, seven of them use PAN-WVC-10
\cite{adler2010detecting}
\cite{adler2011wikipedia}
\cite{gotze2014advanced}
\cite{harpalani2011language}
\cite{mola2012wikipedia}
\cite{wang2010got}
\cite{west2011multilingual},
with the best precision value is $0.86$, recall value $0.57$, and PR-AUC
$0.66$, which obtained by Velasco using Random Forest without resampling on
dataset.
Only two research that use PAN-WVC-11
\cite{gotze2014advanced}
\cite{west2011multilingual}
with the best result obtained by Gotze, $0.92$ on precision, $0.39$
on recall, and $0.74$ on PR-AUC.
