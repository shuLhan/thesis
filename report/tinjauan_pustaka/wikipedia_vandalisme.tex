\label{subsec:bot-wikipedia}
\subsection{Bot Wikipedia}

Permasalahan vandalisme di Wikipedia telah terjadi sejak adanya Wikipedia itu
sendiri.
Komunitas Wikipedia menangani permasalahan tersebut dengan membuat fungsi
pengaman pada artikel secara manual supaya artikel tidak bisa disunting, bila
sebuah artikel terlalu sering divandal.
Sejak tahun 2006, bot pendeteksi vandalisme digunakan, yang secara otomatis
memantau suntingan vandalisme dan terkadang mengembalikannya.
Umumnya bot ini menggunakan aturan heuristik sederhana, daftar hitam kata, dan
daftar alamat \textit{Internet Protocol} (IP) pengguna yang
diblokir yang terdeteksi melakukan vandalisme (contohnya, VoABot II
\footnote{\url{https://en.wikipedia.org/wiki/User:VoABot_II}}
dan ClueBot
\footnote{\url{https://en.wikipedia.org/wiki/User:ClueBot}}).
ClueBot-NG
\footnote{\url{https://en.wikipedia.org/wiki/User:ClueBot_NG}}
menggantikan ClueBot, menggunakan pendekatan pembelajaran mesin.
Bot ini mencoba memperbaiki teknik berbasis heuristik yang susah untuk dirawat
dan mudah dilewat.
Bot ini menggunakan dataset suntingan pra-klasifikasi yang dianotasikan oleh
pengguna Wikipedia untuk melatih Jaringan Saraf Tiruan.
Pengklasifikasinya bekerja pada beberapa fitur suntingan, seperti probabilitas
tingkat-kata vandalisme untuk mengklasifikasi suntingan baru.

\label{subsec:pendekatan-pembelajaran-mesin}
\subsection{Pendekatan Pembelajaran Mesin}

Sejak tahun 2008 deteksi vandalisme di Wikipedia berbasis pendekatan pembelajaran mesin telah menjadi topik penelitian yang menarik.
Potthast \cite{potthast2008automatic} berkontribusi untuk pendekatan deteksi
vandalisme dengan pembelajaran mesin yang pertama menggunakan fitur tekstual
berikut fitur meta data dasar dengan menggunakan pengklasifikasi
\textit{logistic regression}.
Smets \cite{smets08automaticvandalism} menggunakan pengklasifikasi Naive Bayes
pada sekumpulan kata yang merepresentasikan suntingan dan yang pertama
menggunakan model kompresi untuk mendeteksi vandalisme di Wikipedia.
Itakura dan Clarke \cite{itakura2009using} menggunakan Kompresi Markov Dinamis
untuk mendeteksi suntingan vandalisme di Wikipedia.
Mola Velasco \cite{mola2012wikipedia} mengembangkan pendekatan yang dilakukan
oleh Potthast \cite{potthast2008automatic} dengan menambahkan beberapa fitur
tekstual dan berbagai fitur berbasis daftar-kata.
Velasco memenangi \textit{1st International Competition on Wikipedia Vandalism
Detection}.  West dkk. \cite{west2011multilingual} adalah yang pertama
mengajukan sebuah pendekatan deteksi vandalisme hanya berdasarkan meta data
spasial dan temporal, tanpa perlu memeriksa teks pada artikel dan revisi.
Adler dkk. \cite{adler2010detecting} membangun sebuah sistem deteksi vandalisme
menggunakan sistem reputasi WikiTrust.
Adler dkk. \cite{adler2011wikipedia} kemudian menggabungkan bahasa alami,
spasial, temporal, dan fitur reputasi yang digunakan pada karya sebelumnya.
West dan Lee \cite{west2011multilingual} adalah yang pertama memperkenalkan
data \textit{ex post facto} sebagai fitur, yang mana perhitungannya
mempertimbangkan revisi selanjutnya.
Sistem deteksi vandalisme West dan Lee memenangkan \textit{2nd International
Competition on Wikipedia Vandalism Detection}.
Harpalani dkk. \cite{harpalani2011language} menyatakan suntingan vandalisme
memiliki properti lingustik yang unik dan sama.
Harpalani dkk. membangun sistem deteksi vandalisme berdasarkan analisis
\textit{stylometric} dari suntingan vandalisme dengan model probabilitas
\textit{context-free grammar}.
Pendekatan Harpalani dkk. mengalahkan sistem berbasis fitur dengan pola
dangkal, yang menyamakan struktur sintaksis dan token teks.
Mengikuti tren dari klasifikasi vandalisme antar bahasa, Tran dan Christen
\cite{tran2013cross} mengevaluasi berbagai pengklasifikasi berbasiskan pada
sekumpulan fitur independen bahasa yang dikumpulkan dari jumlah artikel dilihat
setiap jam dan riwayat suntingan Wikipedia.

Gotze \cite{gotze2014advanced} menggabungkan fitur dari Adler dkk.
\cite{adler2011wikipedia}, Javanmardi dkk. \cite{javanmardi2011vandalism}, Mola
Velasco \cite{mola2012wikipedia}, Potthast dkk. \cite{potthast2008automatic},
Wang dan McKeown \cite{wang2010got}, dan West dan Lee
\cite{west2011multilingual} dengan empat fitur tambahan dan perubahan.
Gotze mengaplikasikan SMOTE untuk mensampel ulang dataset PAN-WVC-10 dan
PAN-WVC-11.
Untuk mengevaluasi hasil sampel ulang tersebut Gotze berfokus pada
pengaplikasian teknik \textit{Logistic Regression} dan \textit{Random Forest};
dan sebagai tambahan mengikutkan juga pengklasifikasi \textit{RealAdaBoost} dan
\textit{Bayesian Network}.

Dari penelitian di atas, tujuh diantaranya menggunakan PAN-WVC-10
\cite{adler2010detecting}
\cite{adler2011wikipedia}
\cite{gotze2014advanced}
\cite{harpalani2011language}
\cite{mola2012wikipedia}
\cite{wang2010got}
\cite{west2011multilingual},
dengan nilai presisi terbaik yaitu $0,86$, nilai \textit{recall} $0,57$, dan
PR-AUC $0,66$ didapat oleh Velasco menggunakan \textit{Random Forest} tanpa
penyeimbangan dataset.
Hanya dua yang menggunakan PAN-WVC-11 \cite{gotze2014advanced}
\cite{west2011multilingual} dengan hasil terbaik dipegang oleh Gotze yaitu
dengan nilai presisi $0,92$, \textit{recall} $0,39$, dan PR-AUC $0,74$.
