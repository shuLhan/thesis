Permasalahan umum dalam penggalian data atau algoritma pembelajaran ansambel
adalah ketidakmampuan untuk menangani data pelatihan yang timpang.
Ketimpangan antara kelas positif dan negatif biasanya menyebabkan akurasi
deteksi yang rendah.
Simulasi yang dilakukan oleh Strobel dkk. \cite{strobl2007bias} menampilkan
bahwa RF condong mendukung kelas mayoritas.
Saat menggunakan RF untuk deteksi, sejumlah besar sampel negatif dibutuhkan
untuk mendapatkan pengklasifikasi yang kuat dan laju \textit{false-positive}
yang rendah.
Hal ini menyebabkan ketimpangan yang besar antara kelas positif dan
negatif, sehingga membuat pengklasifikasi RF yang berfokus pada kelas
mayoritas.
Kelemahan lain dari RF yaitu setelah belajar dengan beberapa pohon, RF secara
gradual mencapai titik puncaknya, yang mana pengklasifikasi tidak bisa lagi
meningkatkan \textit{sensitivity} pada pendeteksian maupun mengurangi laju
\textit{false-positive}-nya.

Pada tahun 2011, Viola dan Jones mengajukan algoritma deteksi sampel cepat
berbasis AdaBoost dengan struktur kaskade (\textit{cascade})
\cite{viola2004robust}.
Struktur kaskade dimotivasi oleh asumsi bahwa lebih mudah untuk menolak sebuah
sampel yang negatif daripada mencari sampel yang positif.
Viola dan Jones menggabungkan pengklasifikasi yang kuat pada beberapa tingkatan
yang independen dengan kondisi bahwa setiap tingkat dapat menolak sebuah
sampel, sehingga supaya sebuah sampel dapat dianggap positif semua tingkat
harus terlewati.
Disebabkan karena dominasi penolakan pada tahap-tahap awal, waktu komputasi
menjadi berkurang.
Sebagai tambahan, untuk mendapatkan pelatihan yang lebih baik, Viola dan Jones
mengajukan strategi \textit{bootstrap} dengan menghapus sampel yang benar
terklasifikasi negatif setelah pembelajaran dilakukan pada setiap tingkat.
Setelah itu, dataset pelatihan yang berkurang ditambahkan dengan sampel yang
salah diklasifikasi (\textit{false-positive})
\cite{viola2004robust}.

Sebuah pengklasifikasi kaskade terdiri dari sejumlah tingkatan dengan
kompleksitas yang meningkat.
Setiap tingkat minimum memiliki satu pengklasifikasi independen.
Pengklasifikasi ditambahkan ke dalam tingkatan sampai batas nilai
\textit{true-positive} dan \textit{true-negative} tercapai.
Keuntungan dari struktur kaskade yaitu sejumlah besar sampel dapat
didistribusikan diantara tingkatan, berkurangnya nilai \textit{false-positive},
dan berkurangnya waktu komputasi baik pada pelatihan dan klasifikasi.

Bauman menerapkan metoda ini pada RF dan mengajukan \textit{Cascaded Random
Forest} (CRF) yaitu penggabungan dari pengklasifikasi RF dengan struktur
kaskade, yang menyusun beberapa pohon keputusan dalam setiap tingkatan dengan
strategi agregasi \textit{bootstrap}.
Sehingga, pembelajaran pada sampel positif meningkat dan kelemahan dari data
yang timpang terhindari \cite{baumann2013cascaded}.

Pengklasifikasi CRF memiliki enam parameter umum, tiga diantaranya sama dengan
RF yaitu jumlah pohon ($T$), persentase sampel acak untuk \textit{bootstrap},
($b$), dan jumlah fitur acak ($m$).
Tiga parameter lainnya yaitu jumlah tingkatan ($S$), nilai ambang batas
\textit{true-positive} ($maxtp$), dan nilai ambang batas
\textit{true-negative} ($maxtn$).

Strategi \textit{bootstrap} yang digunakan adalah sebagai berikut: setelah
menyelesaikan pembelajaran pada sebuah tingkatan, dataset pelatihan yang berisi
hanya sampel negatif diujikan ke semua tingkatan yang telah dibentuk
sebelumnya dengan tujuan untuk menghapus sampel yang benar bernilai
\textit{true-negative} saja, sehingga dataset pelatihan sebisa mungkin berisi
hanya sampel positif.
Sampel yang terklasifikasi \textit{false-positive} kemudian dimasukan kembali
ke dataset pelatihan untuk dipelajari oleh tingkatan berikutnya.
Algoritma selengkapnya dari CRF dapat dilihat pada lampiran
\ref{lampiran:alg_crf}.

Beberapa tingkatan memiliki akurasi deteksi yang lebih rendah daripada
yang lainnya.
Untuk mengurangi pengaruh tingkatan yang memiliki performansi yang rendah
tersebut, maka dihitung faktor bobot $\alpha$ dari setiap tingkatan dengan
mengeksploitasi rerata harmonik dari \textit{precision} dan \textit{recall}
pada dataset pelatihan atau dikenal juga dengan nilai $F_1$
(\textit{fmeasure}).
Nilai $\alpha$ pada setiap tingkatan secara linear dinormalisasi pada rentang 0
dan 1, sehingga bobot dari tingkat yang memiliki performansi yang rendah
berkurang supaya pengaruhnya terhadap mayoritas \textit{voting} juga berkurang.
Formula untuk mendapatkan hasil dari pengklasifikasi CRF diberikan pada gambar
\ref{form:crf}.

\begin{figure}[h]
\[
	y(x) = argmax \left(
			\frac{1}{T \cdot \sum^{S}_{s=1} \alpha_{s} }
			\sum\limits_{s=1}^{S} \alpha_{s}
			\sum\limits^{T}_{t=1} I_{h_{t} (x) = c}
		\right)
\]
\caption{
Formula untuk mendapatkan kelas (\textit{voting}) pada pengklasifikasi CRF
dengan bobot.
$x$ adalah sampel yang akan diklasifikasi,
$S$ adalah jumlah tingkatan pada struktur kaskade,
$\alpha_{s}$ adalah nilai bobot dari tingkatan,
$T$ adalah jumlah pohon pada tingkatan, dan
$h_{t}$ yaitu fungsi klasifikasi dari sebuah pohon yang memberikan sebuah nilai
kelas $c$ yang bisa memiliki nilai indikator dari $I$
(misalkan nilai 1 untuk positif atau 0 untuk negatif).
}
\label{form:crf}
\end{figure}
