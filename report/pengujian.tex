\chapter{Hasil dan Analisis}

Pelatihan model dilakukan dengan cara menjalankan program klasifikasi RF dan
CRF pada masing-masing dataset fitur WVC2010 yang belum disampel ulang, yang
telah disampel ulang dengan SMOTE, dan yang telah disampel ulang dengan
LNSMOTE.
Setelah modelnya terbangun, model diuji dengan diberikan input dataset fitur
WVC2011. Hasil dari pengujian digunakan untuk analisis.

Lingkungan pelatihan dan pengujian dilakukan pada mesin Intel\textregistered\
 Core\texttrademark \ i7-4750HQ CPU 2,00 GHz, dengan jumlah \textit{RAM} 8
GB. Setiap pelatihan model dilakukan satu per satu untuk menghindari adanya
\textit{cache miss} yang berpengaruh pada kecepatan dan waktu pemrosesan.

\section{Dataset}

Dataset yang digunakan untuk pelatihan model yaitu WVC2010 yang terdiri dari
tiga jenis yaitu dataset tanpa sampel ulang, dataset yang telah disampel ulang
dengan SMOTE, dan dataset yang telah disampel ulang dengan LNSMOTE.
Jumlah sampel pada dataset yang tidak disampel yaitu 2394 positif dan 30045
negatif dengan total 32439 sampel.
Jumlah sampel positif pada dataset hasil sampel ulang dengan SMOTE yaitu 28728
sampel dengan total 58773 sampel.
Jumlah sampel positif pada dataset hasil sampel ulang dengan LNSMOTE yaitu
28588 sampel dengan total 58633 sampel.

Dataset yang digunakan untuk pengujian model yaitu WVC2011 yang terdiri dari
1143 sampel positif dan 8842 sampel negatif dengan total 9985 sampel.
Jumlah fitur pada WVC2011 sama dengan WVC2010 yaitu 26 fitur.

\section{Parameter Pelatihan Model}

Supaya konsisten antara pengklasifikasi, digunakan parameter umum yang sama,
seperti jumlah pohon, jumlah fitur acak, dan persentase \textit{bootstrapping};
yaitu 200 pohon, 5 fitur acak, dan $ 64\% $ untuk \textit{bootstrapping}.
Untuk klasifikasi CRF dilakukan tiga pemodelan dan pengujian dengan parameter
yang berbeda yaitu 200 tingkat dengan 1 pohon, 100 tingkat dengan 2 pohon, dan
50 tingkat dengan 4 pohon; dengan jumlah pohon yang tetap sama yaitu 200.
Hal ini dilakukan untuk melihat pengaruh dari jumlah pohon terhadap tingkat dan
hasil klasifikasi.
Parameter lain pada pemodelan CRF yaitu nilai ambang batas TPR dan TNR diset
pada nilai $0,95$ dan $0,95$ untuk mendapatkan hasil klasifikasi yang bagus dan
jumlah pohon yang konsisten.

\section{Hasil Pengujian}

Hasil pengujian diberikan dalam bentuk performansi pengklasifikasi pada tabel
\ref{tab:stats} dan kecepatan pelatihan model pada tabel
\ref{tab:runtimes}.

\DTLsetseparator{;}
\DTLloaddb{stats}{../result/stats.csv}
\DTLmaxforcolumn{stats}{TPR}{\maxtpr}
\DTLminforcolumn{stats}{FPR}{\minfpr}
\DTLmaxforcolumn{stats}{TNR}{\maxtnr}
\DTLmaxforcolumn{stats}{Presisi}{\maxprec}
\DTLmaxforcolumn{stats}{F-Measure}{\maxfm}
\DTLmaxforcolumn{stats}{Akurasi}{\maxacc}
\DTLmaxforcolumn{stats}{AUC}{\maxauc}

\begin{table}[htbp]
\caption{Performansi Klasifikasi RF dan CRF}
\centering
\footnotesize
\begin{tabular}{p{2cm} p{2cm} rrrrrrr}
\hline
\textbf{Klasifikasi} &
\textbf{Dataset} &
\textbf{TPR} &
\textbf{FPR} &
\textbf{TNR} &
\textbf{Pres.} &
\textbf{F-Mea.} &
\textbf{Aku.} &
\textbf{AUC}
\DTLforeach*{stats}{%
	\cl=Klasifikasi,%
	\ds=Dataset,%
	\tpr=TPR,%
	\fpr=FPR,%
	\tnr=TNR,%
	\prec=Presisi,%
	\fm=F-Measure,%
	\acc=Akurasi,%
	\auc=AUC%
}{%
	\DTLifnullorempty{\cl}
		{\\ \cline{2-9}}
		{\\ \hline \hline}
	\DTLifnullorempty{\cl}
		{}
		{
			\multirow{4}{2cm}{\cl}
		}
	& \ds
	& \DTLifnumeq{\tpr}{\maxtpr}{\textbf{\tpr}}{\tpr}
	& \DTLifnumeq{\fpr}{\minfpr}{\textbf{\fpr}}{\fpr}
	& \DTLifnumeq{\tnr}{\maxtnr}{\textbf{\tnr}}{\tnr}
	& \DTLifnumeq{\prec}{\maxprec}{\textbf{\prec}}{\prec}
	& \DTLifnumeq{\fm}{\maxfm}{\textbf{\fm}}{\fm}
	& \DTLifnumeq{\acc}{\maxacc}{\textbf{\acc}}{\acc}
	& \DTLifnumeq{\auc}{\maxauc}{\textbf{\auc}}{\auc}
}
\\
\hline
\end{tabular}
\label{tab:stats}
\end{table}

\DTLloaddb{runtimes}{../result/runtimes.csv}

\begin{table}[htbp]
\caption{Kecepatan pelatihan model}
\centering
\footnotesize
\begin{tabular}{p{4cm} p{4cm} r}
\hline
\textbf{Klasifikasi} &
\textbf{Dataset} &
\textbf{Waktu (menit)}
\DTLforeach*{runtimes}{%
		\cl=Klasifikasi,
		\ds=Dataset,
		\time=Waktu (menit)%
}{%
	\DTLifnullorempty{\cl}
		{\\ \cline{2-3}}
		{\\ \hline \hline}
	\DTLifnullorempty{\cl}
		{}
		{
			\multirow{3}{4cm}{\cl}
		}
	& \ds
	& \time
}
\\
\hline
\end{tabular}
\label{tab:runtimes}
\end{table}

Klasifikasi CRF LNSMOTE dengan 200 tingkat 1 pohon memberikan nilai TPR paling
tinggi yaitu $0,9904$ tapi dengan nilai FPR yang paling tinggi yaitu $0,8558$
dan TNR yang paling rendah yaitu $0,1442$ di antara model yang lainnya.
Kebalikannya, pengklasifikasi RF tanpa sampel ulang memberikan nilai TNR paling
tinggi yaitu $0,9988$ dan nilai FPR paling rendah yaitu $0,0012$.
Untuk presisi, RF tanpa sampel ulang memberikan nilai tertinggi yaitu $0,9450$,
dan nilai terendah diberikan oleh klasifikasi CRF LNSMOTE dengan 200 tingkat 1
pohon.
Untuk nilai \textit{F-Measure}, nilai tertinggi diberikan oleh klasifikasi CRF
tanpa sampel ulang dengan 50 tingkat dan 4 pohon yaitu $0,5353$, dengan nilai
terendah diberikan oleh klasifikasi CRF LNSMOTE 200 tingkat 1 pohon.
Untuk nilai akurasi tertinggi didapat dengan klasifikasi RF LNSMOTE dengan
yang terendah diberikan oleh klasifikasi CRF LNSMOTE 200 tingkat 1 pohon.
Klasifikasi dengan nilai AUC tertinggi yaitu CRF SMOTE 100 tingkat 2 pohon
dengan yang terendah diberikan oleh klasifikasi CRF tanpa sampel ulang dengan
100 tingkat 2 pohon.

Dari segi kecepatan pelatihan model, pengklasifikasi CRF lebih cepat dari RF
baik pada semua dataset pelatihan.
Sebagai pembanding, dapat dilihat pada klasifikasi RF dan CRF 50 tingkat 4
pohon.
CRF tanpa sampel ulang lebih cepat 11 kali daripada RF, dan pada sampel ulang
SMOTE dan LNSMOTE, klasifikasi CRF 1,6 kali lebih cepat daripada RF.

\input{analisis}
