Deteksi vandalisme di Wikipedia berbasis pendekatan pembelajaran mesin telah
menjadi topik penelitian yang menarik sejak tahun 2008.
\textcite{potthast2008automatic} berkontribusi untuk pendekatan deteksi
vandalisme dengan pembelajaran mesin yang pertama, dengan menggunakan fitur
tekstual berikut fitur meta data dasar dengan menggunakan pengklasifikasi
\textit{logistic regression}.
\textcite{smets08automaticvandalism} menggunakan pengklasifikasi Naive Bayes
pada sekumpulan kata yang merepresentasikan suntingan dan yang pertama
menggunakan model kompresi untuk mendeteksi vandalisme di Wikipedia.
\textcite{itakura2009using} menggunakan Kompresi Markov Dinamis
untuk mendeteksi suntingan vandalisme di Wikipedia.
\textcite{mola2012wikipedia} mengembangkan pendekatan yang dilakukan
oleh \textcite{potthast2008automatic} dengan menambahkan beberapa fitur
tekstual dan berbagai fitur berbasis daftar-kata.
Velasco memenangi \textit{1st International Competition on Wikipedia Vandalism
Detection}.
\textcite{west2011multilingual} adalah yang pertama
mengajukan pendekatan deteksi hanya berdasarkan meta data
spasial dan temporal, tanpa perlu memeriksa teks pada artikel dan revisi.
\textcite{adler2010detecting} membangun sebuah sistem deteksi vandalisme
menggunakan sistem reputasi WikiTrust.
\textcite{adler2011wikipedia} kemudian menggabungkan bahasa alami,
spasial, temporal, dan fitur reputasi yang digunakan pada karya sebelumnya.
\textcite{west2011multilingual} adalah yang pertama memperkenalkan
data \textit{ex post facto} sebagai fitur, yang mana perhitungannya
mempertimbangkan revisi selanjutnya.
Sistem deteksi vandalisme West dan Lee memenangkan \textit{2nd International
Competition on Wikipedia Vandalism Detection}.
\textcite{harpalani2011language} menyatakan suntingan vandalisme
memiliki properti lingustik yang unik dan sama.
Harpalani dkk. membangun sistem deteksi vandalisme berdasarkan analisis
\textit{stylometric} dari suntingan vandalisme dengan model probabilitas
\textit{context-free grammar}.
Pendekatan Harpalani dkk. mengalahkan sistem berbasis fitur dengan pola
dangkal, yang menyamakan struktur sintaksis dan token teks.
Mengikuti tren dari klasifikasi vandalisme antar bahasa,
\textcite{tran2013cross} mengevaluasi berbagai pengklasifikasi berbasiskan pada
sekumpulan fitur independen bahasa yang dikumpulkan dari jumlah artikel dilihat
setiap jam dan riwayat suntingan Wikipedia.

\textcite{gotze2014advanced} menggabungkan fitur dari
\textcite{adler2011wikipedia},
\textcite{javanmardi2011vandalism},
\textcite{mola2012wikipedia},
\textcite{potthast2008automatic},
\textcite{wang2010got}, dan
\textcite{west2011multilingual} dengan empat fitur tambahan dan perubahan.
Untuk mengatasi masalah ketimpangan pada korpus,
\textcite{gotze2014advanced}
mengaplikasikan teknik
\textit{random oversampling}
bernama
\textit{Synthetic Minority Over-sampling TEchnique} (SMOTE)
yang diajukan oleh
\textcite{chawla2002smote},
dan kombinasi dari SMOTE dan
\textit{random undersampling}.
Dataset latihan yang orisinal dan hasil sampel ulang diuji dengan
pengklasifikasi satu-kelas dan dua-kelas.
Pengklasifikasi satu-kelas yang diterapkan diantaranya
\textcite{hempstalk2008one}
dan SVM oleh
\textcite{scholkopf1999support}
yang diimplementasikan oleh
\textcite{chang2011libsvm}
pada korpus PAN-WVC.
Pengklasifikasi dua-kelas yang diterapkan diantaranya
\textit{Logistic Regression},
\textit{RealAdaBoost},
\textit{Random Forest} (RF), dan
\textit{Bayesian Network}.
Hasil percobaan yang didapat memperlihatkan performansi pengklasifikasi
satu-kelas tidak kompetitif dengan satu pun pengklasifikasi dua-kelas.
Hal ini bisa disebabkan karena tidak sesuainya kelompok fitur yang digunakan
untuk menjelaskan suntingan vandalisme, sebagaimana juga parameter pengaturan
yang tidak sesuai pada pendekatan yang digunakan.
Hasil dari pelatihan pada dataset orisinal memperlihatkan RF
lebih unggul dari pengklasifikasi lainnya.
Hasil dari pelatihan pada dataset hasil sampel ulang memperlihatkan adanya
peningkatan pada semua pengklasifikasi kecuali pada RF.



Dari penelitian di atas, tujuh diantaranya menggunakan PAN-WVC-10
\parencites{adler2010detecting}
{adler2011wikipedia}
{gotze2014advanced}
{harpalani2011language}
{mola2012wikipedia}
{wang2010got}
{west2011multilingual},
dengan nilai presisi terbaik yaitu $0,86$, nilai \textit{recall} $0,57$, dan
PR-AUC $0,66$ didapat oleh Velasco menggunakan \textit{Random Forest} tanpa
penyeimbangan dataset.
Hanya dua yang menggunakan PAN-WVC-11
\parencites{gotze2014advanced}
{west2011multilingual}
dengan hasil terbaik dipegang oleh Gotze yaitu
dengan nilai presisi $0,92$, \textit{recall} $0,39$, dan PR-AUC $0,74$.
